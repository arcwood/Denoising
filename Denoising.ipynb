{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zFbhY7vINeLN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from glob import glob\n",
        "from PIL import Image,ImageOps\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "tuuCEsekNpnX"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## creating Dataset\n",
        "random.seed(1)\n",
        "IMAGE_SIZE = 128\n",
        "BATCH_SIZE = 4\n",
        "MAX_TRAIN_IMAGES = 300"
      ],
      "metadata": {
        "id": "3Z3boGXsNrk9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "2UyYDIigXcv0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def autocontrast(tensor, cutoff=0):\n",
        "    tensor = tf.cast(tensor, dtype=tf.float32)\n",
        "    min_val = tf.reduce_min(tensor)\n",
        "    max_val = tf.reduce_max(tensor)\n",
        "    range_val = max_val - min_val\n",
        "    adjusted_tensor = tf.clip_by_value(tf.cast(tf.round((tensor - min_val - cutoff) * (255 / (range_val - 2 * cutoff))), tf.uint8), 0, 255)\n",
        "    return adjusted_tensor\n",
        "\n",
        "def read_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image = autocontrast(image)\n",
        "    image.set_shape([None, None, 3])\n",
        "    image = tf.cast(image, dtype=tf.float32) / 255\n",
        "    return image\n",
        "\n",
        "\n",
        "def random_crop(low_image, enhanced_image):\n",
        "    low_image_shape = tf.shape(low_image)[:2]\n",
        "    low_w = tf.random.uniform(\n",
        "        shape=(), maxval=low_image_shape[1] - IMAGE_SIZE + 1, dtype=tf.int32\n",
        "    )\n",
        "    low_h = tf.random.uniform(\n",
        "        shape=(), maxval=low_image_shape[0] - IMAGE_SIZE + 1, dtype=tf.int32\n",
        "    )\n",
        "    enhanced_w = low_w\n",
        "    enhanced_h = low_h\n",
        "    low_image_cropped = low_image[\n",
        "        low_h : low_h + IMAGE_SIZE, low_w : low_w + IMAGE_SIZE\n",
        "    ]\n",
        "    enhanced_image_cropped = enhanced_image[\n",
        "        enhanced_h : enhanced_h + IMAGE_SIZE, enhanced_w : enhanced_w + IMAGE_SIZE\n",
        "    ]\n",
        "    return low_image_cropped, enhanced_image_cropped\n",
        "\n",
        "\n",
        "def load_data(low_light_image_path, enhanced_image_path):\n",
        "    low_light_image = read_image(low_light_image_path)\n",
        "    enhanced_image = read_image(enhanced_image_path)\n",
        "    low_light_image, enhanced_image = random_crop(low_light_image, enhanced_image)\n",
        "    return low_light_image, enhanced_image\n",
        "\n",
        "\n",
        "def get_dataset(low_light_images, enhanced_images):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((low_light_images, enhanced_images))\n",
        "    dataset = dataset.map(load_data, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "2RfoOw5TXnjd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_low_light_images = sorted(glob(\"/content/drive/MyDrive/vlg24/Train/low/*\"))[:MAX_TRAIN_IMAGES]\n",
        "train_enhanced_images = sorted(glob(\"/content/drive/MyDrive/vlg24/Train/high/*\"))[:MAX_TRAIN_IMAGES]\n",
        "\n",
        "val_low_light_images = sorted(glob(\"/content/drive/MyDrive/vlg24/Train/low/*\"))[MAX_TRAIN_IMAGES:]\n",
        "val_enhanced_images = sorted(glob(\"/content/drive/MyDrive/vlg24/Train/high/*\"))[MAX_TRAIN_IMAGES:]"
      ],
      "metadata": {
        "id": "g4soaeLXXqyB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = get_dataset(train_low_light_images, train_enhanced_images)\n",
        "val_dataset = get_dataset(val_low_light_images, val_enhanced_images)"
      ],
      "metadata": {
        "id": "Dq_3Fuh5YIJO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def transformer_network():\n",
        "    inputs = tf.keras.layers.Input(shape=(None, None, 3))\n",
        "    batch_size = tf.shape(inputs)[0]\n",
        "\n",
        "    conv1 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    conv1 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')(conv1)\n",
        "\n",
        "    conv2 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')(conv1)\n",
        "    conv2 = tf.keras.layers.Conv2D(64, (3, 3), padding='same', activation='relu')(conv2)\n",
        "\n",
        "    conv3 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')(conv2)\n",
        "    conv3 = tf.keras.layers.Conv2D(128, (3, 3), padding='same', activation='relu')(conv2)\n",
        "\n",
        "    res1 = residual_block(conv3, 128)\n",
        "    res2 = residual_block(res1, 128)\n",
        "    res3 = residual_block(res2, 128)\n",
        "    res4 = residual_block(res3, 128)\n",
        "    res5 = residual_block(res4, 128)\n",
        "\n",
        "    deconv1 = tf.keras.layers.Conv2DTranspose(64, (3, 3), padding='same', activation='relu')(res5)\n",
        "    deconv2 = tf.keras.layers.Conv2DTranspose(32, (3, 3), padding='same', activation='relu')(deconv1)\n",
        "\n",
        "    outputs = tf.keras.layers.Conv2D(3, (3, 3), padding='same', activation='sigmoid')(deconv2)\n",
        "    outputs=tf.keras.layers.add([inputs, outputs])\n",
        "\n",
        "    model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "\n",
        "def residual_block(inputs, filters):\n",
        "    x = tf.keras.layers.Conv2D(filters, (3, 3), padding='same', activation='relu')(inputs)\n",
        "    x = tf.keras.layers.Conv2D(filters, (3, 3), padding='same')(x)\n",
        "    x = tf.keras.layers.add([inputs, x])\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "GudOHglHYKMO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False\n",
        "outputs = [vgg.get_layer('block3_conv3').output, vgg.get_layer('block4_conv3').output]\n",
        "model1 = tf.keras.models.Model(inputs=vgg.input, outputs=outputs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDUcBEbEYOcV",
        "outputId": "95501205-de03-44e8-8978-16c8dcb93518"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80134624/80134624 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def perceptual_loss(y_true, y_pred):\n",
        "    y_true_features = model1(y_true)\n",
        "    y_pred_features = model1(y_pred)\n",
        "    loss = tf.reduce_mean(tf.square(y_true_features[0] - y_pred_features[0])) + tf.reduce_mean(tf.square(y_true_features[1] - y_pred_features[1]))\n",
        "    return loss\n",
        "def charbonnier_loss(y_true, y_pred):\n",
        "    return tf.reduce_mean(tf.sqrt(tf.square(y_true - y_pred) + tf.square(1e-3)))\n",
        "def loss(y_true,y_pred):\n",
        "    return  + 0.5*perceptual_loss(y_true, y_pred)  + 0.4*charbonnier_loss(y_true, y_pred)"
      ],
      "metadata": {
        "id": "RqS1NvogYQU6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def peak_signal_noise_ratio(y_true, y_pred):\n",
        "    return tf.image.psnr(y_pred, y_true, max_val=1.0)"
      ],
      "metadata": {
        "id": "wCmRWrqOYSu_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = transformer_network()"
      ],
      "metadata": {
        "id": "ccbTlJxDYUZi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
        "model.compile(\n",
        "    optimizer=optimizer, loss=loss, metrics=[peak_signal_noise_ratio]\n",
        ")"
      ],
      "metadata": {
        "id": "jM5Y-K5dYW-X"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_dataset,validation_data=val_dataset,epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_JIIA_iYYdO",
        "outputId": "ca635fdd-95c1-449c-8044-a1f3c5e12011"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "75/75 [==============================] - 216s 3s/step - loss: 9.1123 - peak_signal_noise_ratio: 15.0955 - val_loss: 7.1481 - val_peak_signal_noise_ratio: 17.0640\n",
            "Epoch 2/50\n",
            "75/75 [==============================] - 18s 233ms/step - loss: 7.3680 - peak_signal_noise_ratio: 16.4283 - val_loss: 6.7372 - val_peak_signal_noise_ratio: 18.0571\n",
            "Epoch 3/50\n",
            "75/75 [==============================] - 17s 223ms/step - loss: 6.1180 - peak_signal_noise_ratio: 17.4618 - val_loss: 5.3842 - val_peak_signal_noise_ratio: 19.0046\n",
            "Epoch 4/50\n",
            "75/75 [==============================] - 17s 225ms/step - loss: 5.8715 - peak_signal_noise_ratio: 18.1625 - val_loss: 5.4815 - val_peak_signal_noise_ratio: 19.2720\n",
            "Epoch 5/50\n",
            "75/75 [==============================] - 16s 206ms/step - loss: 5.3916 - peak_signal_noise_ratio: 18.1750 - val_loss: 5.1786 - val_peak_signal_noise_ratio: 19.2150\n",
            "Epoch 6/50\n",
            "75/75 [==============================] - 16s 206ms/step - loss: 5.1000 - peak_signal_noise_ratio: 18.3790 - val_loss: 4.5718 - val_peak_signal_noise_ratio: 19.5164\n",
            "Epoch 7/50\n",
            "75/75 [==============================] - 17s 228ms/step - loss: 5.0128 - peak_signal_noise_ratio: 18.3770 - val_loss: 4.6464 - val_peak_signal_noise_ratio: 19.7240\n",
            "Epoch 8/50\n",
            "75/75 [==============================] - 16s 208ms/step - loss: 4.9207 - peak_signal_noise_ratio: 18.4513 - val_loss: 4.4684 - val_peak_signal_noise_ratio: 19.3681\n",
            "Epoch 9/50\n",
            "75/75 [==============================] - 15s 203ms/step - loss: 4.5296 - peak_signal_noise_ratio: 18.5999 - val_loss: 4.1345 - val_peak_signal_noise_ratio: 19.5756\n",
            "Epoch 10/50\n",
            "75/75 [==============================] - 16s 206ms/step - loss: 4.4951 - peak_signal_noise_ratio: 18.7860 - val_loss: 4.2578 - val_peak_signal_noise_ratio: 19.5581\n",
            "Epoch 11/50\n",
            "75/75 [==============================] - 15s 204ms/step - loss: 4.3057 - peak_signal_noise_ratio: 18.3006 - val_loss: 4.1623 - val_peak_signal_noise_ratio: 19.8261\n",
            "Epoch 12/50\n",
            "75/75 [==============================] - 17s 227ms/step - loss: 4.2769 - peak_signal_noise_ratio: 18.3823 - val_loss: 4.0616 - val_peak_signal_noise_ratio: 19.3774\n",
            "Epoch 13/50\n",
            "75/75 [==============================] - 17s 226ms/step - loss: 4.2337 - peak_signal_noise_ratio: 18.6340 - val_loss: 4.0535 - val_peak_signal_noise_ratio: 19.6419\n",
            "Epoch 14/50\n",
            "75/75 [==============================] - 16s 209ms/step - loss: 4.1349 - peak_signal_noise_ratio: 18.7066 - val_loss: 4.2109 - val_peak_signal_noise_ratio: 19.0700\n",
            "Epoch 15/50\n",
            "75/75 [==============================] - 22s 298ms/step - loss: 4.3155 - peak_signal_noise_ratio: 18.5034 - val_loss: 3.9476 - val_peak_signal_noise_ratio: 19.4343\n",
            "Epoch 16/50\n",
            "75/75 [==============================] - 16s 217ms/step - loss: 4.1152 - peak_signal_noise_ratio: 18.6896 - val_loss: 3.6009 - val_peak_signal_noise_ratio: 19.7457\n",
            "Epoch 17/50\n",
            "75/75 [==============================] - 17s 230ms/step - loss: 4.0661 - peak_signal_noise_ratio: 18.5545 - val_loss: 3.7089 - val_peak_signal_noise_ratio: 19.3539\n",
            "Epoch 18/50\n",
            "75/75 [==============================] - 16s 210ms/step - loss: 4.1234 - peak_signal_noise_ratio: 18.3951 - val_loss: 3.7766 - val_peak_signal_noise_ratio: 19.7642\n",
            "Epoch 19/50\n",
            "75/75 [==============================] - 17s 231ms/step - loss: 3.8065 - peak_signal_noise_ratio: 18.6545 - val_loss: 3.8025 - val_peak_signal_noise_ratio: 19.4453\n",
            "Epoch 20/50\n",
            "75/75 [==============================] - 18s 232ms/step - loss: 3.7832 - peak_signal_noise_ratio: 18.5045 - val_loss: 4.0174 - val_peak_signal_noise_ratio: 19.3703\n",
            "Epoch 21/50\n",
            "75/75 [==============================] - 16s 207ms/step - loss: 3.7328 - peak_signal_noise_ratio: 18.5733 - val_loss: 3.6778 - val_peak_signal_noise_ratio: 19.9884\n",
            "Epoch 22/50\n",
            "75/75 [==============================] - 17s 227ms/step - loss: 3.6933 - peak_signal_noise_ratio: 18.5759 - val_loss: 3.4492 - val_peak_signal_noise_ratio: 19.6100\n",
            "Epoch 23/50\n",
            "75/75 [==============================] - 17s 228ms/step - loss: 3.8899 - peak_signal_noise_ratio: 18.5915 - val_loss: 3.6571 - val_peak_signal_noise_ratio: 19.6831\n",
            "Epoch 24/50\n",
            "75/75 [==============================] - 16s 211ms/step - loss: 3.8887 - peak_signal_noise_ratio: 18.6167 - val_loss: 3.8078 - val_peak_signal_noise_ratio: 19.6992\n",
            "Epoch 25/50\n",
            "75/75 [==============================] - 16s 213ms/step - loss: 3.9238 - peak_signal_noise_ratio: 18.6508 - val_loss: 4.2542 - val_peak_signal_noise_ratio: 19.5445\n",
            "Epoch 26/50\n",
            "75/75 [==============================] - 17s 232ms/step - loss: 4.0148 - peak_signal_noise_ratio: 18.6920 - val_loss: 3.8913 - val_peak_signal_noise_ratio: 19.4449\n",
            "Epoch 27/50\n",
            "75/75 [==============================] - 17s 228ms/step - loss: 3.6575 - peak_signal_noise_ratio: 18.5601 - val_loss: 3.9470 - val_peak_signal_noise_ratio: 19.4629\n",
            "Epoch 28/50\n",
            "75/75 [==============================] - 17s 232ms/step - loss: 3.7481 - peak_signal_noise_ratio: 18.6808 - val_loss: 3.5168 - val_peak_signal_noise_ratio: 19.9912\n",
            "Epoch 29/50\n",
            "75/75 [==============================] - 18s 236ms/step - loss: 3.7008 - peak_signal_noise_ratio: 18.5196 - val_loss: 3.6177 - val_peak_signal_noise_ratio: 19.5145\n",
            "Epoch 30/50\n",
            "75/75 [==============================] - 17s 230ms/step - loss: 3.7004 - peak_signal_noise_ratio: 18.6438 - val_loss: 3.6989 - val_peak_signal_noise_ratio: 19.3618\n",
            "Epoch 31/50\n",
            "75/75 [==============================] - 17s 232ms/step - loss: 3.6955 - peak_signal_noise_ratio: 18.5720 - val_loss: 4.1151 - val_peak_signal_noise_ratio: 19.5603\n",
            "Epoch 32/50\n",
            "75/75 [==============================] - 17s 231ms/step - loss: 3.5206 - peak_signal_noise_ratio: 18.7552 - val_loss: 3.3031 - val_peak_signal_noise_ratio: 19.8512\n",
            "Epoch 33/50\n",
            "75/75 [==============================] - 16s 207ms/step - loss: 3.8807 - peak_signal_noise_ratio: 18.5152 - val_loss: 3.5455 - val_peak_signal_noise_ratio: 19.8230\n",
            "Epoch 34/50\n",
            "75/75 [==============================] - 17s 226ms/step - loss: 3.4822 - peak_signal_noise_ratio: 18.8649 - val_loss: 3.8884 - val_peak_signal_noise_ratio: 19.4765\n",
            "Epoch 35/50\n",
            "75/75 [==============================] - 16s 210ms/step - loss: 3.6965 - peak_signal_noise_ratio: 18.8013 - val_loss: 4.0360 - val_peak_signal_noise_ratio: 20.0381\n",
            "Epoch 36/50\n",
            "75/75 [==============================] - 17s 228ms/step - loss: 3.5949 - peak_signal_noise_ratio: 18.7458 - val_loss: 3.9294 - val_peak_signal_noise_ratio: 19.4319\n",
            "Epoch 37/50\n",
            "75/75 [==============================] - 16s 208ms/step - loss: 3.6726 - peak_signal_noise_ratio: 18.5512 - val_loss: 3.9574 - val_peak_signal_noise_ratio: 19.7585\n",
            "Epoch 38/50\n",
            "75/75 [==============================] - 16s 208ms/step - loss: 3.6956 - peak_signal_noise_ratio: 18.7242 - val_loss: 3.6489 - val_peak_signal_noise_ratio: 19.8158\n",
            "Epoch 39/50\n",
            "75/75 [==============================] - 16s 211ms/step - loss: 3.4904 - peak_signal_noise_ratio: 18.4704 - val_loss: 4.0682 - val_peak_signal_noise_ratio: 19.4717\n",
            "Epoch 40/50\n",
            "75/75 [==============================] - 17s 226ms/step - loss: 3.7084 - peak_signal_noise_ratio: 18.4966 - val_loss: 3.7076 - val_peak_signal_noise_ratio: 19.6661\n",
            "Epoch 41/50\n",
            "75/75 [==============================] - 17s 229ms/step - loss: 3.7847 - peak_signal_noise_ratio: 18.8350 - val_loss: 3.5365 - val_peak_signal_noise_ratio: 19.6474\n",
            "Epoch 42/50\n",
            "75/75 [==============================] - 17s 230ms/step - loss: 3.5307 - peak_signal_noise_ratio: 18.5778 - val_loss: 3.6792 - val_peak_signal_noise_ratio: 19.5195\n",
            "Epoch 43/50\n",
            "75/75 [==============================] - 17s 219ms/step - loss: 3.6949 - peak_signal_noise_ratio: 18.6604 - val_loss: 3.6952 - val_peak_signal_noise_ratio: 19.6219\n",
            "Epoch 44/50\n",
            "75/75 [==============================] - 17s 229ms/step - loss: 3.6156 - peak_signal_noise_ratio: 18.7140 - val_loss: 4.0831 - val_peak_signal_noise_ratio: 19.4900\n",
            "Epoch 45/50\n",
            "75/75 [==============================] - 17s 227ms/step - loss: 3.3859 - peak_signal_noise_ratio: 18.4550 - val_loss: 3.4436 - val_peak_signal_noise_ratio: 19.4968\n",
            "Epoch 46/50\n",
            "75/75 [==============================] - 16s 209ms/step - loss: 3.5122 - peak_signal_noise_ratio: 18.6057 - val_loss: 3.7755 - val_peak_signal_noise_ratio: 19.4214\n",
            "Epoch 47/50\n",
            "75/75 [==============================] - 17s 225ms/step - loss: 3.6042 - peak_signal_noise_ratio: 18.5979 - val_loss: 4.0093 - val_peak_signal_noise_ratio: 19.3147\n",
            "Epoch 48/50\n",
            "75/75 [==============================] - 16s 206ms/step - loss: 3.5515 - peak_signal_noise_ratio: 18.8310 - val_loss: 3.5142 - val_peak_signal_noise_ratio: 19.6410\n",
            "Epoch 49/50\n",
            "75/75 [==============================] - 16s 215ms/step - loss: 3.6920 - peak_signal_noise_ratio: 18.7305 - val_loss: 3.6164 - val_peak_signal_noise_ratio: 19.5782\n",
            "Epoch 50/50\n",
            "75/75 [==============================] - 17s 227ms/step - loss: 3.6251 - peak_signal_noise_ratio: 18.5609 - val_loss: 3.4220 - val_peak_signal_noise_ratio: 19.6403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_results(images, titles, figure_size=(12, 12)):\n",
        "    fig = plt.figure(figsize=figure_size)\n",
        "    for i in range(len(images)):\n",
        "        fig.add_subplot(1, len(images), i + 1).set_title(titles[i])\n",
        "        _ = plt.imshow(images[i])\n",
        "        plt.axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def infer(original_image):\n",
        "    image = tf.keras.preprocessing.image.img_to_array(original_image)\n",
        "    image = autocontrast(image)\n",
        "    image = tf.cast(image,dtype=tf.float32) / 255.0\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    output = model.predict(image,verbose=0)\n",
        "    output_image = output[0] * 255.0\n",
        "    output_image = output_image.clip(0, 255)\n",
        "    output_image = output_image.reshape(\n",
        "        (np.shape(output_image)[0], np.shape(output_image)[1], 3)\n",
        "    )\n",
        "    output_image = Image.fromarray(np.uint8(output_image))\n",
        "    original_image = Image.fromarray(np.uint8(original_image))\n",
        "    return output_image"
      ],
      "metadata": {
        "id": "rwNe8slyYaR-"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_psnr = 0.0\n",
        "num_samples = 0\n",
        "\n",
        "def calculate_psnr(true_image, generated_image):\n",
        "    return tf.image.psnr(true_image, generated_image, max_val=1.0)\n",
        "\n",
        "# Iterate over the dataset\n",
        "for low_light, normal_light in val_dataset:\n",
        "    # Generate enhanced images using the generator\n",
        "    generated_images = model.predict(low_light)\n",
        "\n",
        "    # Calculate PSNR for each pair in the batch\n",
        "    for i in range(len(normal_light)):\n",
        "        psnr_score = calculate_psnr(normal_light[i], generated_images[i])\n",
        "        total_psnr += psnr_score.numpy()\n",
        "        num_samples += 1\n",
        "\n",
        "# Compute the average PSNR score\n",
        "average_psnr = total_psnr / num_samples\n",
        "print(f\"Average PSNR: {average_psnr:.2f} dB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3ZHb_HPYePj",
        "outputId": "fd90866b-acc5-49e2-cea4-427147e90e48"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 271ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "1/1 [==============================] - 0s 51ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "1/1 [==============================] - 0s 48ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "1/1 [==============================] - 0s 46ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "1/1 [==============================] - 0s 41ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 69ms/step\n",
            "1/1 [==============================] - 0s 67ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Average PSNR: 19.63 dB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Average PSNR: {average_psnr:.2f} dB\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kiMsYYp_YoFH",
        "outputId": "c3610097-f9ce-4144-f387-c78e838cce39"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average PSNR: 19.63 dB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G3zRGsTWafb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YwXKZzfEbR-V"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}